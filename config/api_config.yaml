# name: str
#     model_name: str
#     endpoints: default to null
#         - api_base: str
#           api_key: str
#           api_version: str optional (only for azure)
#     api_type: str
#     tokenizer: str optional (to optimize token limits)
#     parallel: int

gpt-3.5-turbo-0125:
    model_name: gpt-3.5-turbo-0125
    endpoints: null
    api_type: openai
    parallel: 8

gpt-4-0314:
    model_name: gpt-4-0314
    endpoints: null
    api_type: openai
    parallel: 8

gpt-4-1106-preview:
    model_name: gpt-4-1106-preview
    endpoints: null
    api_type: openai
    parallel: 8

Qwen/Qwen1.5-72B-Chat:
    model_name: "Qwen/Qwen1.5-72B-Chat"
    models: ["Qwen/Qwen1.5-72B-Chat"]
    candidate_count: 1
    temperature: 0.7
    endpoints: null
    api_type: together_ai
    parallel: 1

Qwen/Qwen1.5-110B-Chat:
    model_name: "Qwen/Qwen1.5-110B-Chat"
    models: ["Qwen/Qwen1.5-110B-Chat"]
    candidate_count: 1
    temperature: 0.7
    endpoints: null
    api_type: together_ai
    parallel: 1

microsoft/WizardLM-2-8x22B:
    model_name: "microsoft/WizardLM-2-8x22B"
    models: ["microsoft/WizardLM-2-8x22B"]
    candidate_count: 1
    temperature: 0.7
    endpoints: null
    api_type: together_ai
    parallel: 1

mistralai/Mixtral-8x22B-Instruct-v0.1:
    model_name: "mistralai/Mixtral-8x22B-Instruct-v0.1"
    models: ["mistralai/Mixtral-8x22B-Instruct-v0.1"]
    candidate_count: 1
    temperature: 0.7
    endpoints: null
    api_type: together_ai
    parallel: 1

meta-llama/Llama-3-70b-chat-hf:
    model_name: "meta-llama/Llama-3-70b-chat-hf"
    models: ["meta-llama/Llama-3-70b-chat-hf"]
    candidate_count: 1
    temperature: 0.7
    endpoints: null
    api_type: together_ai
    parallel: 1

databricks/dbrx-instruct:
    model_name: "databricks/dbrx-instruct"
    models: ["databricks/dbrx-instruct"]
    candidate_count: 1
    temperature: 0.7
    endpoints: null
    api_type: together_ai
    parallel: 1